{
    "connectors": [
        {
            "provider": "anthropic",
            "models": [
                {
                    "tier": "high",
                    "slug": "claude-3-opus-20240229",
                    "alias": "claude-3-opus",
                    "model_type": "text2text",
                    "context_window": 200000,
                    "input_cost_per_token": 0.000015,
                    "output_cost_per_token": 0.000075,
                    "group": "claude",
                    "available_on_free_plan": false,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 1,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "medium",
                    "slug": "claude-3-sonnet-20240229",
                    "alias": "claude-3-sonnet",
                    "model_type": "text2text",
                    "context_window": 200000,
                    "input_cost_per_token": 0.000003,
                    "output_cost_per_token": 0.000015,
                    "group": "claude",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 1,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "claude-3-haiku-20240307",
                    "alias": "claude-3-haiku",
                    "model_type": "text2text",
                    "context_window": 200000,
                    "input_cost_per_token": 0.00000025,
                    "output_cost_per_token": 0.00000125,
                    "group": "claude",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 1,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "claude-2",
                    "alias": "claude-2",
                    "deprecated": true,
                    "model_type": "text2text",
                    "context_window": 200000,
                    "input_cost_per_token": 0.000008,
                    "output_cost_per_token": 0.000024
                },
                {
                    "slug": "claude-instant-1",
                    "alias": "claude-instant",
                    "deprecated": true,
                    "model_type": "text2text",
                    "context_window": 100000,
                    "input_cost_per_token": 0.00000163,
                    "output_cost_per_token": 0.00000551
                }
            ]
        },
        {
            "provider": "cohere",
            "models": [
                {
                    "tier": "low",
                    "slug": "command-light",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000003,
                    "output_cost_per_token": 0.0000006,
                    "alias": "command-light",
                    "group": "command",
                    "deprecated": true,
                    "finetuning": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "command",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000003,
                    "output_cost_per_token": 0.0000006,
                    "alias": "command",
                    "group": "command",
                    "deprecated": true,
                    "finetuning": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "command-r",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "input_cost_per_token": 0.0000005,
                    "output_cost_per_token": 0.0000015,
                    "alias": "command-r",
                    "group": "command",
                    "finetuning": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 4000,
                            "min": 0,
                            "max": 4000
                        },
                        "top_p": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "medium",
                    "slug": "command-r-plus",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "input_cost_per_token": 0.000003,
                    "output_cost_per_token": 0.000015,
                    "alias": "command-r-plus",
                    "group": "command",
                    "finetuning": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 4000,
                            "min": 0,
                            "max": 4000
                        },
                        "top_p": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": 0.0,
                            "max": 1.0
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "embed-english-v3.0",
                    "model_type": "text2vector",
                    "alias": "embed-english",
                    "output_cost_per_token": 0.0000001,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "embed-english-light-v3.0",
                    "model_type": "text2vector",
                    "alias": "embed-english-light",
                    "output_cost_per_token": 0.0000001,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "embed-multilingual-v3.0",
                    "model_type": "text2vector",
                    "alias": "embed-multilingual",
                    "output_cost_per_token": 0.0000001,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "embed-multilingual-light-v3.0",
                    "model_type": "text2vector",
                    "alias": "embed-multilingual-light",
                    "output_cost_per_token": 0.0000001,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "coral",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.000001,
                    "output_cost_per_token": 0.000002,
                    "alias": "coral",
                    "group": "others",
                    "deprecated": true
                }
            ]
        },
        {
            "provider": "azure-mistral",
            "models": [
                {
                    "tier": "medium",
                    "slug": "mistral-large",
                    "model_type": "text2text",
                    "context_window": 32768,
                    "input_cost_per_token": 0.000004,
                    "output_cost_per_token": 0.000012,
                    "alias": "mistral-large",
                    "group": "mistral",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 32768,
                            "min": 0,
                            "max": 32768
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                }
            ]
        },
        {
            "provider": "azure",
            "models": [
                {
                    "tier": "high",
                    "slug": "gpt-4-32k-azure",
                    "model_type": "text2text",
                    "context_window": 32768,
                    "input_cost_per_token": 0.00006,
                    "output_cost_per_token": 0.00012,
                    "alias": "gpt-4-eu",
                    "group": "gpt",
                    "available_on_free_plan": false,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 32768,
                            "min": 0,
                            "max": 32768
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "gpt-4-azure",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "input_cost_per_token": 0.00003,
                    "output_cost_per_token": 0.00006,
                    "deprecated": true
                },
                {
                    "slug": "gpt-35-turbo-azure",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000015,
                    "output_cost_per_token": 0.000002,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "gpt-35-turbo-16k-azure",
                    "model_type": "text2text",
                    "context_window": 16385,
                    "input_cost_per_token": 0.0000005,
                    "output_cost_per_token": 0.0000015,
                    "alias": "gpt-3.5-turbo-eu",
                    "group": "gpt",
                    "finetuning": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 16385,
                            "min": 0,
                            "max": 16385
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                }
            ]
        },
        {
            "provider": "openai",
            "models": [
                {
                    "tier": "medium",
                    "slug": "gpt-4-turbo-preview",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "input_cost_per_token": 0.00001,
                    "output_cost_per_token": 0.00003,
                    "alias": "gpt-4-turbo",
                    "group": "gpt",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "medium",
                    "slug": "gpt-4o",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "input_cost_per_token": 0.000005,
                    "output_cost_per_token": 0.000015,
                    "alias": "gpt-4o",
                    "group": "gpt",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "gpt-4-0125-preview",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "input_cost_per_token": 0.00001,
                    "output_cost_per_token": 0.00003,
                    "deprecated": true
                },
                {
                    "slug": "gpt-4-1106-preview",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "input_cost_per_token": 0.00001,
                    "output_cost_per_token": 0.00003,
                    "deprecated": true
                },
                {
                    "slug": "gpt-4",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "input_cost_per_token": 0.00003,
                    "output_cost_per_token": 0.00006,
                    "deprecated": true
                },
                {
                    "slug": "gpt-3.5-turbo-1106",
                    "model_type": "text2text",
                    "context_window": 16385,
                    "input_cost_per_token": 0.0000015,
                    "output_cost_per_token": 0.000002,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "gpt-3.5-turbo",
                    "model_type": "text2text",
                    "context_window": 16385,
                    "input_cost_per_token": 0.0000005,
                    "output_cost_per_token": 0.0000015,
                    "alias": "gpt-3.5-turbo",
                    "group": "gpt",
                    "finetuning": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "gpt-3.5-turbo-16k",
                    "model_type": "text2text",
                    "context_window": 16385,
                    "input_cost_per_token": 0.0000015,
                    "output_cost_per_token": 0.000002,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "text-embedding-3-small",
                    "model_type": "text2vector",
                    "alias": "text-embedding-3-small",
                    "context_window": 8191,
                    "input_cost_per_token": 0.00000002,
                    "output_dimension": 1536,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "text-embedding-3-large",
                    "model_type": "text2vector",
                    "alias": "text-embedding-3-large",
                    "context_window": 8191,
                    "input_cost_per_token": 0.00000013,
                    "output_dimension": 3072,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "text-embedding-ada-002",
                    "model_type": "text2vector",
                    "alias": "text-embedding-ada-002",
                    "context_window": 8191,
                    "input_cost_per_token": 0.0000001,
                    "output_dimension": 1536,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "medium",
                    "slug": "dall-e-3",
                    "model_type": "text2image",
                    "cost_per_image": 0.120,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                }
            ]
        },
        {
            "provider": "cloudflare",
            "models": [
                {
                    "slug": "@cf/meta/llama-2-7b-chat-fp16",
                    "model_type": "text2text",
                    "context_window": 3072,
                    "deprecated": true
                },
                {
                    "slug": "@cf/meta/llama-2-7b-chat-int8",
                    "model_type": "text2text",
                    "context_window": 2048,
                    "deprecated": true
                },
                {
                    "slug": "@cf/mistral/mistral-7b-instruct-v0.1",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "@cf/baai/bge-base-en-v1.5",
                    "model_type": "text2vector",
                    "alias": "bge-base-en",
                    "context_window": 512,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "@cf/baai/bge-large-en-v1.5",
                    "model_type": "text2vector",
                    "alias": "bge-large-en",
                    "context_window": 512,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "@cf/baai/bge-small-en-v1.5",
                    "model_type": "text2vector",
                    "alias": "bge-small-en",
                    "context_window": 512,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "@hf/thebloke/llamaguard-7b-awq",
                    "model_type": "text2text",
                    "context_window": 2048,
                    "deprecated": true
                },
                {
                    "slug": "@hf/thebloke/neural-chat-7b-v3-1-awq",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "@hf/thebloke/codellama-7b-instruct-awq",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "@hf/thebloke/llama-2-13b-chat-awq",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "@hf/thebloke/deepseek-coder-6.7b-base-awq",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "deprecated": true
                },
                {
                    "slug": "@hf/thebloke/openhermes-2.5-mistral-7b-awq",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
                    "model_type": "text2text",
                    "context_window": 16384,
                    "deprecated": true
                },
                {
                    "slug": "@hf/thebloke/zephyr-7b-beta-awq",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                }
            ]
        },
        {
            "provider": "deepinfra",
            "models": [
                {
                    "slug": "deepinfra/meta-llama/Llama-2-7b-chat-hf",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "deepinfra/meta-llama/Llama-2-70b-chat-hf",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "deepinfra/codellama/CodeLlama-34b-Instruct-hf",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "deepinfra/meta-llama/Llama-2-13b-chat-hf",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "deepinfra/deepinfra/airoboros-70b",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "deepinfra/mistralai/Mistral-7B-Instruct-v0.1",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                }
            ]
        },
        {
            "provider": "fireworksai",
            "models": [
                {
                    "slug": "accounts/fireworks/models/mixtral-8x7b-instruct",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000008,
                    "deprecated": true
                },
                {
                    "slug": "accounts/fireworks/models/yi-34b-200k-capybara",
                    "model_type": "text2text",
                    "context_window": 204800,
                    "input_cost_per_token": 0.0000007,
                    "output_cost_per_token": 0.0000028,
                    "deprecated": true
                },
                {
                    "slug": "accounts/fireworks/models/mistral-7b-instruct-4k",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000008,
                    "deprecated": true
                },
                {
                    "slug": "accounts/fireworks/models/llama-v2-13b-code-instruct",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000008,
                    "deprecated": true
                },
                {
                    "slug": "accounts/fireworks/models/llama-v2-34b-code-instruct",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000007,
                    "output_cost_per_token": 0.0000028,
                    "deprecated": true
                },
                {
                    "slug": "accounts/fireworks/models/llama-v2-7b-chat",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000008,
                    "deprecated": true
                },
                {
                    "slug": "accounts/fireworks/models/llama-v2-13b-chat",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000008,
                    "deprecated": true
                },
                {
                    "slug": "accounts/fireworks/models/llama-v2-70b-chat",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000007,
                    "output_cost_per_token": 0.0000028,
                    "deprecated": true
                }
            ]
        },
        {
            "provider": "octoai",
            "models": [
                {
                    "slug": "octoai/mistral-7b-instruct-fp16",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000001,
                    "output_cost_per_token": 0.0000025,
                    "deprecated": true
                },
                {
                    "slug": "octoai/codellama-70b-instruct-fp16",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000006,
                    "output_cost_per_token": 0.0000019,
                    "deprecated": true
                },
                {
                    "slug": "octoai/llama-2-13b-chat-fp16",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.000005,
                    "deprecated": true
                },
                {
                    "slug": "octoai/llama-2-70b-chat-fp16",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000006,
                    "output_cost_per_token": 0.000019,
                    "deprecated": true
                },
                {
                    "slug": "octoai/llama-2-70b-chat-int4",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000006,
                    "output_cost_per_token": 0.000012,
                    "deprecated": true
                },
                {
                    "slug": "octoai/codellama-7b-instruct-fp16",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000001,
                    "output_cost_per_token": 0.000025,
                    "deprecated": true
                },
                {
                    "slug": "octoai/codellama-13b-instruct-fp16",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.000005,
                    "deprecated": true
                },
                {
                    "slug": "octoai/codellama-34b-instruct-fp16",
                    "model_type": "text2text",
                    "context_window": 16384,
                    "input_cost_per_token": 0.0000005,
                    "output_cost_per_token": 0.00000115,
                    "deprecated": true
                },
                {
                    "slug": "octoai/codellama-34b-instruct-int4",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000005,
                    "output_cost_per_token": 0.0000008,
                    "deprecated": true
                },
                {
                    "slug": "octoai/mixtral-8x7b-instruct-fp16",
                    "model_type": "text2text",
                    "context_window": 32768,
                    "input_cost_per_token": 0.0000003,
                    "output_cost_per_token": 0.0000005,
                    "deprecated": true
                }
            ]
        },
        {
            "provider": "replicate",
            "models": [
                {
                    "slug": "meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "meta/llama-2-7b-chat:13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "mistralai/mistral-7b-instruct-v0.1:83b6a56e7c828e667f21fd596c338fd4f0039b46bcfa18d973e8e70e455fda70",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "mistralai/mistral-7b-v0.1:3e8a0fb6d7812ce30701ba597e5080689bef8a013e5c6a724fafb108cc2426a0",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "replicate/all-mpnet-base-v2:b6b7585c9640cd7a9572c6e129c9549d79c9c31f0d3fdce7baac7c67ca38f305",
                    "model_type": "text2vector",
                    "alias": "all-mpnet-base-v2",
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                }
            ]
        },
        {
            "provider": "together",
            "models": [
                {
                    "slug": "togethercomputer/CodeLlama-13b-Instruct",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "input_cost_per_token": 0.00000022,
                    "output_cost_per_token": 0.00000022,
                    "deprecated": true
                },
                {
                    "slug": "togethercomputer/CodeLlama-34b-Instruct",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "input_cost_per_token": 0.0000008,
                    "output_cost_per_token": 0.0000008,
                    "deprecated": true
                },
                {
                    "slug": "togethercomputer/CodeLlama-7b-Instruct",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000002,
                    "deprecated": true
                },
                {
                    "slug": "togethercomputer/llama-2-13b-chat",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.00000022,
                    "output_cost_per_token": 0.00000022,
                    "deprecated": true
                },
                {
                    "slug": "togethercomputer/llama-2-70b-chat",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000009,
                    "output_cost_per_token": 0.0000009,
                    "deprecated": true
                },
                {
                    "slug": "togethercomputer/llama-2-7b-chat",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000002,
                    "deprecated": true
                },
                {
                    "slug": "togethercomputer/Llama-2-7B-32K-Instruct",
                    "model_type": "text2text",
                    "context_window": 32768,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000002,
                    "deprecated": true
                },
                {
                    "slug": "mistralai/Mistral-7B-Instruct-v0.1",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000002,
                    "deprecated": true
                },
                {
                    "slug": "NousResearch/Nous-Hermes-llama-2-7b",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000002,
                    "deprecated": true
                },
                {
                    "slug": "NousResearch/Nous-Hermes-Llama2-13b",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000003,
                    "output_cost_per_token": 0.0000003,
                    "deprecated": true
                },
                {
                    "slug": "NousResearch/Nous-Hermes-Llama2-70b",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "input_cost_per_token": 0.0000009,
                    "output_cost_per_token": 0.0000009,
                    "deprecated": true
                },
                {
                    "slug": "Open-Orca/Mistral-7B-OpenOrca",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000002,
                    "deprecated": true
                }
            ]
        },
        {
            "provider": "mistralai",
            "models": [
                {
                    "tier": "low",
                    "slug": "mistral-tiny",
                    "model_type": "text2text",
                    "context_window": 32000,
                    "input_cost_per_token": 0.00000025,
                    "output_cost_per_token": 0.00000025,
                    "alias": "mistral-tiny",
                    "group": "mistral",
                    "deprecated": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "mistral-small-latest",
                    "model_type": "text2text",
                    "context_window": 32000,
                    "input_cost_per_token": 0.000001,
                    "output_cost_per_token": 0.000003,
                    "alias": "mistral-small",
                    "group": "mistral",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "mistral-medium",
                    "model_type": "text2text",
                    "context_window": 32000,
                    "input_cost_per_token": 0.0000027,
                    "output_cost_per_token": 0.0000081,
                    "alias": "mistral-medium",
                    "group": "mistral",
                    "deprecated": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "mistral-embed",
                    "model_type": "text2vector",
                    "alias": "mistral-embed",
                    "context_window": 4096,
                    "available_on_free_plan": true,
                    "input_cost_per_token": 0.0000001,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                }
            ]
        },
        {
            "provider": "prem",
            "models": [
                {
                    "tier": "low",
                    "slug": "phi1_5",
                    "model_type": "text2text",
                    "context_window": 2048,
                    "available_on_free_plan": true,
                    "group": "slm",
                    "environment": [
                        "development",
                        "staging"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "phi2",
                    "model_type": "text2text",
                    "context_window": 2048,
                    "available_on_free_plan": true,
                    "group": "slm",
                    "environment": [
                        "development",
                        "staging"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "tiny_llama",
                    "model_type": "text2text",
                    "context_window": 2048,
                    "available_on_free_plan": true,
                    "group": "slm",
                    "environment": [
                        "development",
                        "staging"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "mamba",
                    "model_type": "text2text",
                    "context_window": 128,
                    "available_on_free_plan": true,
                    "group": "slm",
                    "environment": [
                        "development",
                        "staging"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "stable_lm2",
                    "model_type": "text2text",
                    "context_window": 2048,
                    "available_on_free_plan": true,
                    "group": "slm",
                    "environment": [
                        "development",
                        "staging"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "gemma",
                    "model_type": "text2text",
                    "context_window": 2048,
                    "available_on_free_plan": true,
                    "group": "slm",
                    "environment": [
                        "development",
                        "staging"
                    ]
                },
                {

                    "tier": "low",
                    "slug": "prem-1b-chat",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "available_on_free_plan": true,
                    "group": "slm",
                    "environment": [
                        "development",
                        "staging"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "prem-1b-json",
                    "model_type": "text2text",
                    "coming_soon": true,
                    "group": "slm",
                    "environment": [
                        "development"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "prem-1b-sum",
                    "model_type": "text2text",
                    "coming_soon": true,
                    "group": "slm",
                    "environment": [
                        "development"
                    ]
                }
            ]
        },
        {
            "provider": "openrouter",
            "models": [
                {
                    "tier": "low",
                    "slug": "openrouter/meta-llama/llama-3-8b-instruct",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "llama-3-8b-instruct",
                    "uncensored": false,
                    "group": "llama",
                    "input_cost_per_token": 0.00000017,
                    "output_cost_per_token": 0.0000007,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "openrouter/meta-llama/llama-3-70b-instruct",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "llama-3-70b-instruct",
                    "uncensored": false,
                    "group": "llama",
                    "input_cost_per_token": 0.0000007,
                    "output_cost_per_token": 0.0000007,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/openrouter/auto",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/jondurbin/bagel-34b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/jebcarter/psyfighter-13b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/koboldai/psyfighter-13b-2",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/neversleep/noromaid-mixtral-8x7b-instruct",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/nousresearch/nous-hermes-llama2-13b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/meta-llama/codellama-34b-instruct",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/phind/phind-codellama-34b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/intel/neural-chat-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/mistralai/mixtral-8x7b-instruct",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/nousresearch/nous-hermes-2-mixtral-8x7b-sft",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/haotian-liu/llava-13b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/nousresearch/nous-hermes-2-vision-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/meta-llama/llama-2-13b-chat",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/migtissera/synthia-70b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "openrouter/pygmalionai/mythalion-13b",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "mythalion-13b",
                    "uncensored": true,
                    "group": "uncensored",
                    "input_cost_per_token": 0.0000013,
                    "output_cost_per_token": 0.0000013,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 400,
                            "min": 0,
                            "max": 400
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/undi95/remm-slerp-l2-13b-6k",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true,
                    "group": "others",
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 128000,
                            "min": 0,
                            "max": 128000
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    }
                },
                {
                    "tier": "low",
                    "slug": "openrouter/gryphe/mythomax-l2-13b",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "mythomax-l2-13b",
                    "uncensored": true,
                    "input_cost_per_token": 0.00000035,
                    "output_cost_per_token": 0.00000035,
                    "group": "uncensored",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/xwin-lm/xwin-lm-70b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/gryphe/mythomax-l2-13b-8k",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/alpindale/goliath-120b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/neversleep/noromaid-20b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/gryphe/mythomist-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/mancer/weaver",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/nousresearch/nous-capybara-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/codellama/codellama-70b-instruct",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/teknium/openhermes-2-mistral-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/teknium/openhermes-2.5-mistral-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "openrouter/undi95/remm-slerp-l2-13b",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "remm-slerp-l2-13b",
                    "uncensored": true,
                    "group": "uncensored",
                    "input_cost_per_token": 0.00000097,
                    "output_cost_per_token": 0.00000097,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/undi95/toppy-m-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/openrouter/cinematika-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "openrouter/01-ai/yi-34b-chat",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "yi-34-chat",
                    "group": "others",
                    "input_cost_per_token": 0.00000072,
                    "output_cost_per_token": 0.00000072,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/01-ai/yi-34b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/01-ai/yi-6b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "openrouter/togethercomputer/stripedhyena-nous-7b",
                    "model_type": "text2text",
                    "context_window": 32768,
                    "alias": "stripedhyena-nous-7b",
                    "uncensored": true,
                    "group": "uncensored",
                    "input_cost_per_token": 0.00000018,
                    "output_cost_per_token": 0.00000018,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 32768,
                            "min": 0,
                            "max": 32768
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/togethercomputer/stripedhyena-hessian-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/mistralai/mixtral-8x7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/nousresearch/nous-hermes-yi-34b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/nousresearch/nous-hermes-2-mistral-7b-dpo",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/open-orca/mistral-7b-openorca",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "openrouter/huggingfaceh4/zephyr-7b-beta",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "zephyr-7b-beta",
                    "uncensored": true,
                    "group": "uncensored",
                    "input_cost_per_token": 0.0000002,
                    "output_cost_per_token": 0.0000002,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/google/palm-2-chat-bison",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/google/palm-2-codechat-bison",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/google/palm-2-chat-bison-32k",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/google/palm-2-codechat-bison-32k",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "tier": "medium",
                    "slug": "openrouter/google/gemini-pro",
                    "model_type": "text2text",
                    "context_window": 91728,
                    "alias": "gemini-pro",
                    "group": "gemini",
                    "input_cost_per_token": 0.000000125,
                    "output_cost_per_token": 0.000000375,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 22937,
                            "min": 0,
                            "max": 22937
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/meta-llama/llama-2-70b-chat",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/nousresearch/nous-capybara-34b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/jondurbin/airoboros-l2-70b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "openrouter/austism/chronos-hermes-13b",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "chronos-hermes-13b",
                    "uncensored": true,
                    "group": "uncensored",
                    "input_cost_per_token": 0.00000013,
                    "output_cost_per_token": 0.00000013,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "openrouter/mistralai/mixtral-8x22b",
                    "model_type": "text2text",
                    "context_window": 65536,
                    "alias": "mixtral-8x22b",
                    "uncensored": false,
                    "input_cost_per_token": 0.00000099,
                    "output_cost_per_token": 0.00000099,
                    "group": "mistral",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 65536,
                            "min": 0,
                            "max": 65536
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/mistralai/mistral-7b-instruct",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/openchat/openchat-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/lizpreciatior/lzlv-70b-fp16-hf",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "tier": "low",
                    "slug": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
                    "model_type": "text2text",
                    "context_window": 32769,
                    "alias": "dolphin-mixtral-8x7b",
                    "group": "mistral",
                    "input_cost_per_token": 0.00000037,
                    "output_cost_per_token": 0.00000037,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 32769,
                            "min": 0,
                            "max": 32769
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "openrouter/rwkv/rwkv-5-world-3b",
                    "model_type": "text2text",
                    "context_window": 10000,
                    "alias": "rwkv-5-world-3b",
                    "uncensored": true,
                    "group": "uncensored",
                    "input_cost_per_token": 0.0,
                    "output_cost_per_token": 0.0,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 10000,
                            "min": 0,
                            "max": 10000
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "openrouter/recursal/rwkv-5-3b-ai-town",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/recursal/eagle-7b",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                },
                {
                    "slug": "openrouter/google/gemma-7b-it",
                    "model_type": "text2text",
                    "context_window": 128000,
                    "deprecated": true
                }
            ]
        },
        {
            "provider": "perplexity",
            "models": [
                {
                    "slug": "perplexity/codellama-34b-instruct",
                    "model_type": "text2text",
                    "context_window": 16384,
                    "deprecated": true
                },
                {
                    "slug": "perplexity/codellama-70b-instruct",
                    "model_type": "text2text",
                    "context_window": 16384,
                    "deprecated": true
                },
                {
                    "slug": "perplexity/llama-2-70b-chat",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "deprecated": true
                },
                {
                    "slug": "perplexity/mistral-7b-instruct",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "deprecated": true
                },
                {
                    "slug": "perplexity/mixtral-8x7b-instruct",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "deprecated": true
                },
                {
                    "slug": "perplexity/pplx-7b-chat",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "pplx-7b-chat",
                    "group": "mistral",
                    "deprecated": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 1.99
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "perplexity/pplx-70b-chat",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "pplx-70b-chat",
                    "group": "llama",
                    "deprecated": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 1.99
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "perplexity/pplx-7b-online",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "pplx-7b-online",
                    "group": "mistral",
                    "deprecated": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 1.99
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "perplexity/pplx-70b-online",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "pplx-70b-online",
                    "group": "llama",
                    "deprecated": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 1.99
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                }
            ]
        },
        {
            "provider": "anyscale",
            "models": [
                {
                    "slug": "anyscale/meta-llama/Llama-2-7b-chat-hf",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "llama-2-7b-chat",
                    "group": "llama",
                    "deprecated": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.01,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "anyscale/meta-llama/Llama-2-13b-chat-hf",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "llama-2-13b-chat",
                    "group": "llama",
                    "finetuning": true,
                    "deprecated": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.01,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "anyscale/meta-llama/Llama-2-70b-chat-hf",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "llama-2-70b-chat",
                    "group": "llama",
                    "finetuning": true,
                    "deprecated": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.01,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "anyscale/codellama/CodeLlama-70b-Instruct-hf",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "codellama-70b-instruct",
                    "group": "llama",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.01,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "anyscale/mistralai/Mistral-7B-Instruct-v0.1",
                    "model_type": "text2text",
                    "context_window": 16384,
                    "alias": "mistral-7b-instruct-v0.1",
                    "uncensored": true,
                    "group": "mistral",
                    "finetuning": true,
                    "parameters": {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 16384,
                            "min": 0,
                            "max": 16384
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.01,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1",
                    "model_type": "text2text",
                    "context_window": 32768,
                    "alias": "mixtral-8x7b-instruct-v0.1",
                    "group": "mistral",
                    "finetuning": true,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 32768,
                            "min": 0,
                            "max": 32768
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.01,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "anyscale/google/gemma-7b-it",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "gemma-7b-it",
                    "group": "gemini",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.01,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "anyscale/thenlper/gte-large",
                    "model_type": "text2vector",
                    "alias": "gte-large",
                    "context_window": 512,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "anyscale/BAAI/bge-large-en-v1.5",
                    "model_type": "text2vector",
                    "alias": "bge-large-en-v1.5",
                    "context_window": 512,
                    "available_on_free_plan": true,
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                }
            ]
        },
        {
            "provider": "groq",
            "models": [
                {
                    "tier": "low",
                    "slug": "groq/llama3-8b-8192",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "llama-3-8b-fast",
                    "group": "llama",
                    "input_cost_per_token": 0.00000005,
                    "output_cost_per_token": 0.0000001,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "groq/llama3-70b-8192",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "llama-3-70b-fast",
                    "input_cost_per_token": 0.00000059,
                    "output_cost_per_token": 0.00000079,
                    "group": "llama",
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "slug": "groq/llama2-70b-4096",
                    "model_type": "text2text",
                    "context_window": 4096,
                    "alias": "llama-2-70b-fast",
                    "group": "llama",
                    "deprecated": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 4096,
                            "min": 0,
                            "max": 4096
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "groq/mixtral-8x7b-32768",
                    "model_type": "text2text",
                    "context_window": 32768,
                    "alias": "mixtral-8x7b-fast",
                    "group": "mistral",
                    "input_cost_per_token": 0.00000027,
                    "output_cost_per_token": 0.00000027,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 32768,
                            "min": 0,
                            "max": 32768
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                },
                {
                    "tier": "low",
                    "slug": "groq/gemma-7b-it",
                    "model_type": "text2text",
                    "context_window": 8192,
                    "alias": "gemma-7b-it-fast",
                    "group": "gemini",
                    "input_cost_per_token": 0.0000001,
                    "output_cost_per_token": 0.0000001,
                    "available_on_free_plan": true,
                    "parameters":
                    {
                        "temperature": {
                            "default": 1.0,
                            "min": 0.0,
                            "max": 2.0
                        },
                        "max_tokens": {
                            "default": 8192,
                            "min": 0,
                            "max": 8192
                        },
                        "top_p": {
                            "default": 0.5,
                            "min": 0.0,
                            "max": 1.0
                        },
                        "frequency_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        },
                        "presence_penalty": {
                            "default": 0.0,
                            "min": -2,
                            "max": 2
                        }
                    },
                    "environment": [
                        "development",
                        "staging",
                        "production"
                    ]
                }
            ]
        }
    ]
}
